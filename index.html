<!DOCTYPE html>
<html>
<head>
<title>XRF55: A Radio Frequency Dataset for Human Indoor Action Analysis</title>
<style>
body {
  background-color: white;
  text-align: center;
  color: black;
  font-family: Arial, Helvetica, sans-serif;
}
</style>
</head>
<body>

<center>
	<br>
    <span style="font-size:36px">XRF55: A Radio Frequency Dataset for Human Indoor Action Analysis</span><br><br>
    <table align=center width=600px>
	  			  <tr>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:18px"><a href="https://github.com/WhisperYi/XRF55">Yizhe Lv</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:18px"><a href="https://github.com/WhisperYi/XRF55">Mengdie Zhu</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:18px"><a href="https://scholar.google.com/citations?user=LKPpmXQAAAAJ&hl=en">Fei Wang</a></span>
		  		  		</center>
		  		  	  </td>
			  </table><br>
     <span style="font-size:18px">Xi'an Jiaotong University, Shaanxi</span><br>
     <span style="font-size:18px">In ICCV 2023</span><br><br>
      <table align=center width=300px>
	  			  <tr>
	  	              <td align=center width=50px>
	  					<center>
	  						<span style="font-size:24px"><a href='https://github.com/WhisperYi/XRF55'>[Paper]</a>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=50px>
	  					<center>
	  						<span style="font-size:24px"><a href='https://github.com/WhisperYi/XRF55'>[GitHub]</a></span>
		  		  		</center>
		  		  	  </td>
			  </table>
</center>
<table align=center width=850px>
  			  <tr>
  	              <td width=400px>
  					<center>
  	                	<a href="images/teaser_v3.jpg"><img class="" src = "images/teaser_v3.jpg" height="360px"></img></href></a><br>
					</center>
  	              </td>
                </tr>
  	              <td width=400px>
                      <center>
  	                	<span style="font-size:14px"><i>XRF55 includes 55 human indoor action classes which we categorize into 5 types: Human-Object Interaction, Human-Human Interaction, Fitness, Body Motion, and Human-Computer Interaction..</i>
                      <center>
  	              </td>

  		  </table>
          
          <table align=center width=850px>
	  		  <center><h1>Abstract</h1></center>
	  		  <tr>
	  		  	<td>
	  		    </td>
	  		  </tr>
			</table>
				We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.
  		  <br><br>
		  <hr>

			<center><h1>Paper</h1></center>
			<table align="center" width="700" px="">
			          <tbody><tr>
			          <td><a href="https://github.com/WhisperYi/XRF55"><img class="layered-paper-big" style="height:175px" src="images/paper_pdf_thumb.png"></a></td>
			          <td><br><br><br><span style="font-size:12pt">Yizhe Lv, Mengdie Zhu, Fei Wang</span><br>
			          <b><span style="font-size:12pt">XRF55: A Radio Frequency Dataset for Human Indoor Action Analysis</span></b><br>
			          <span style="font-size:12pt">ICCV, 2023 (<a href="https://github.com/WhisperYi/XRF55">Paper</a>)</span>
			          </td>
								</tr>
					</table>
								<br>
          <table align="center" width="600px">
            <tbody>
              <tr>
                <td>
                  <center>
                    <span style="font-size:22px">
                      <a href="./resources/bibtex_cvpr_pix2pix.txt" target="_blank">[bibtex]</a>
                    </span>
                  </center>
                </td>
              </tr>
            </tbody>
          </table>
			
		  <br><br>

          <hr>
          
          <center><h1>Download our dataset</h1></center>

  		  <table align=center width=800px>
			  <tr><center>
				<!-- <span style="font-size:28px">Code coming soon!</span></i>			  	 -->
				<div style="width:600px; text-align:center">
					<span style="font-size:28px">&nbsp;Wi-Fi dataset:<a href='https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix '>[Click here]</a></span><br>
					<span style="font-size:28px">&nbsp;RFID dataset: <a href='https://github.com/phillipi/pix2pix'>[Click here]</a></span><br>
                    <span style="font-size:28px">&nbsp;mmWave dataset: <a href='https://github.com/phillipi/pix2pix'>[Click here]</a></span><br>
                    <span style="font-size:28px">&nbsp;Kinect dataset: <a href='https://github.com/phillipi/pix2pix'>[Click here]</a></span><br>
				</div>
                    <br>

			  <br>
			  </center></tr>
		  </table>
          <br>
		  <hr>
          
          <center><h1>Slides and network structure</h1></center>
     		  <br>
     		  <table align=center width=1100px>
     			  <tr>
     	              <td width=300px>
     					<center>
     						<span style="font-size:22px"><a href="images/XYZ55.pptx">Slides</a></span><br>
                            <iframe width="560" height="315" src="images/XYZ55.pptx" frameborder="0" allowfullscreen></iframe>
                        </center>
     	              </td>

     	              <td width=300px>
     					<center>
     						<span style="font-size:22px"><a href='images/color_palettes.jpg'>Network structure</a></span><br>
     	                	<a href="'images/color_palettes.jpg"><img src="'images/color_palettes.jpg" width = "270px"></a><br>
     	              </td>

                   </tr>
     		  </table>
		  <br><br>
          <hr>
	<table align=center width=1100px>
		  <tr>
              <td width=400px>
     					<left>
      		  <center><h1>Prospect </h1></center>
              People can use our dataset for many creative applications,  due to the synchronized Kinect, we envision XRF55 will support and facilitate the exploration of action detection, action segmentation, pose estimation, human parsing, mesh reconstruction<br><br>

      		  <table align=center width=1100px>
							<tr>
      	              <td width=300px>
      					<center>
      						<span style="font-size:22px"><a href='https://www.nvidia.com/en-us/deep-learning-ai/ai-art-gallery/artists/scott-eaton/'>Human Allocation of Space</a></span><br>
      	                	<a href="https://www.nvidia.com/en-us/deep-learning-ai/ai-art-gallery/artists/scott-eaton/"><img src="images/color_palettes.jpg" width = "250px"></a><br>
      					<div style="width:250px; text-align:left; font-size:14px"><a href="http://www.scott-eaton.com/">Scott Eaton</a> uses a customized version of pix2pix as a tool in his artwork, for example training a net to <a href="https://vimeo.com/345881421">translate from sketches and brush strokes to 3D renderings</a>. The sculpture above is an actual brozne cast derived from one of Scott's translated designs. You can find more of his AI-empowered artwork <a href="http://www.scott-eaton.com/category/creativeai">here</a>.</div></center>
      	              </td>

      	              <td width=300px>
      					<center>
      						<span style="font-size:22px"><a href='https://vimeo.com/260612034'>Learning to See: Gloomy Sunday</a></span><br>
      	                	<a href="https://vimeo.com/260612034"><img src="images/color_palettes.jpg" width = "250px"></a><br>
      					<div style="width:250px; text-align:left; font-size:14px"><a href="http://www.memo.tv/">Memo Akten</a> used pix2pix to create the very compelling music video linked above, in which common household items, like a powercord, are moved around in a pantomine of crashing waves and blooming flowers. Then a pix2pix-based model translates the pantomine into renderings of the imagined objects.</div></center>
      	              </td>

      	              <td width=300px>
      					<center>
      						<span style="font-size:22px"><a href='https://nono.ma/suggestive-drawing'>Suggestive Drawing</a></span><br>
      	                	<a href="https://nono.ma/suggestive-drawing"><img src="images/color_palettes.jpg" width = "250px"></a><br>
      					<div style="width:250px; text-align:left; font-size:14px"><a href="https://nono.ma/">Nono Martinez Alonso</a> used pix2pix for his masters thesis on human-AI collaboration for design. Different pix2pix models are used as aids for a human designer, where they "suggest" extensions, refinements, and completions of the designer's sketches.</div></center>
      	              </td>

              </tr>
										
      			  <tr>
      	              <td width=300px>
												<br>
      					<center>
      						<span style="font-size:22px"><a href='https://twitter.com/search?vertical=default&q=edges2cats&src=typd'>#edges2cats</a></span><br>
      	                	<a href="https://twitter.com/search?vertical=default&q=edges2cats&src=typd"><img src="images/color_palettes.jpg" width = "250px"></a><br>
      					<div style="width:250px; text-align:left; font-size:14px"><a href="https://twitter.com/christophrhesse?lang=en">Christopher Hesse</a> trained our model on converting edge maps to photos of cats, and included this in his <a href="https://affinelayer.com/pixsrv/">interactive demo</a>. Apparently, this is what the Internet wanted most, and #edges2cats briefly <a href="https://www.youtube.com/watch?v=vbuE5CLRCDY">went viral</a>. The above cats were designed by Vitaly Vidmirov (<a href="https://twitter.com/vvid/status/834976420942204933">@vvid</a>).</div></center>
      	              </td>

      	              <td width=300px>
      					<center>
      						<span style="font-size:22px"><a href='https://www.youtube.com/watch?v=af_9LXhcebY'>Alternative Face</a></span><br>
      	                	<a href="https://www.youtube.com/watch?v=af_9LXhcebY"><img src="images/color_palettes.jpg" width = "250px"></a><br>
      					<div style="width:250px; text-align:left; font-size:14px"><a href="https://quasimondo.com/">Mario Klingemann</a> used our code to translate the appearance of French singer Francoise Hardy onto Kellyanne Conway's infamous "alternative facts" interview. Interesting articles about it can be read <a href="http://nymag.com/selectall/2017/03/pix2pix-cat-drawing-tool-is-ai-at-its-best.html">here</a> and <a href="http://www.alphr.com/art/1005324/alternative-face-the-machine-that-puts-kellyanne-conway-s-words-into-a-french-singer-s">here</a>.</div></center>
      	              </td>

      	              <td width=300px>
      					<center>
      						<span style="font-size:22px"><a href='https://twitter.com/brannondorsey/status/808461108881268736'>Person-to-Person</a></span><br>
      	                	<a href="https://twitter.com/brannondorsey/status/808461108881268736"><img src="images/color_palettes.jpg" width = "250px"></a><br>
      					<div style="width:250px; text-align:left; font-size:14px"><a href="https://brannondorsey.com/">Brannon Dorsey</a> recorded himself mimicking frames from a video of Ray Kurzweil giving a talk. He then used this data to train a Dorsey&rarr;Kurzweil translator, allowing him to become a kind of puppeter in control of Kurzweil's appearance.</div></center>
      	              </td>

                    </tr>

                    <tr>
        	              <td width=300px>
                              <br>
        					<center>
        						<span style="font-size:22px"><a href='https://twitter.com/bgondouin/status/818571935529377792'>Interactive Anime</a></span><br>
        	                	<a href="https://twitter.com/bgondouin/status/818571935529377792"><img src="images/color_palettes.jpg" width = "250px"></a><br>
        					<div style="width:250px; text-align:left; font-size:14px"><a href="https://bgon.github.io/">Bertrand Gondouin</a> trained our method to translate sketches&rarr;Pokemon, resulting in an interactive drawing tool.</div></center>
        	              </td>

        	              <td width=300px>
                              <br>
        					<center>
        						<span style="font-size:22px"><a href='http://www.k4ai.com/imageops/index.html'>Background masking</a></span><br>
        	                	<a href="http://www.k4ai.com/imageops/index.html"><img src="images/color_palettes.jpg" width = "250px"></a><br>
        					<div style="width:250px; text-align:left; font-size:14px"><a href="https://twitter.com/kaihuchen?lang=en">Kaihu Chen</a> performed <a href="http://www.k4ai.com/tag/gan/index.html">a number of interesting experiments</a> using our method, including getting it to mask out the background of a portrait as shown above.</div></center>
        	              </td>

      	              <td width=300px>
                          <br>
      					<center>
      						<span style="font-size:22px"><a href='http://colormind.io/blog/'>Color palette completion</a></span><br>
      	                	<a href="http://colormind.io/blog/"><img src="images/color_palettes.jpg" width = "250px"></a><br>
      					<div style="width:250px; text-align:left; font-size:14px"><a href="http://colormind.io/blog/">Colormind</a> adapted our code to predict a complete 5-color palette given a subset of the palette as input. This application stretches the definition of what counts as "image-to-image translation" in an exciting way: if you can visualize your input/output data as images, then image-to-image methods are applicable! (not that this is necessarily the best choice of representation, just one to think about.)</div></center>
      	              </td>

                    </tr>
      		  </table>
              <br>
        </td>
    </tr>
</table>
<br>
<hr>

  		  <table align=center width=1100px>
  			  <tr>
  	              <td>
  					<left>
	  		  <center><h1>Acknowledgements</h1></center>
					We thank XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX.
			</left>
		</td>
			 </tr>
		</table>

		<br><br>
</body>
</html>

