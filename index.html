<!DOCTYPE html>
<html>
<head>
<title>XYZ55: A temporary dataset for human indoor motion analysis</title>
<style>
body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight:300;
		font-size:17px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-weight:300;
        font-size: 30px;
	}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
    table td, table td * {
        vertical-align: top;
    }
	
	    /* 幻灯片容器 */
.slideshow-container {
  max-width: 560px;
  position: relative;
  margin: auto;
}
 
/* 下一张 & 上一张 按钮 */
.prev, .next {
  cursor: pointer;
  position: absolute;
  top: 50%;
  width: auto;
  margin-top: -22px;
  padding: 16px;
  color: rgb(102, 102, 102);
  font-weight: bold;
  font-size: 18px;
  transition: 0.6s ease;
  border-radius: 5px 0 0 5px;
}
 /* 定位 "下一张" 按钮靠右 */
.prev {
  left: 0;
}
/* 定位 "下一张" 按钮靠右 */
.next {
  right: 0;
  border-radius: 0 5px 5px 0;
}
 
/* On hover, add a black background color with a little bit see-through */
.prev:hover, .next:hover {
  background-color: rgba(0,0,0,0.8);
}
 
/* 标题文本 */
.text {
  color: #f2f2f2;
  font-size: 15px;
  padding: 8px 12px;
  position: absolute;
  bottom: 8px;
  width: 100%;
  text-align: center;
}
 
/* 数字文本 (1/3 等) */
.numbertext {
  color: #f2f2f2;
  font-size: 12px;
  padding: 8px 12px;
  position: absolute;
  top: 0;
}
 
/* 标记符号 */
.dot {
  cursor:pointer;
  height: 13px;
  width: 13px;
  margin: 0 2px;
  background-color: #bbb;
  border-radius: 50%;
  display: inline-block;
  transition: background-color 0.6s ease;
}
 
.active, .dot:hover {
  background-color: #717171;
}
 
/* 淡出动画 */
.fade {
  -webkit-animation-name: fade;
  -webkit-animation-duration: 1.5s;
  animation-name: fade;
  animation-duration: 1.5s;
}
 
@-webkit-keyframes fade {
  from {opacity: .4} 
  to {opacity: 1}
}
 
@keyframes fade {
  from {opacity: .4} 
  to {opacity: 1}
}
</style>
</head>
<body>

<center>
	<br>
    <span style="font-size:35px">XYZ55: A temporary dataset for human indoor motion analysis</span><br><br>
    <table align=center width=600px>
	  			  <tr>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:18px"><a href="https://github.com/WhisperYi/XRF55">Yizhe Lv</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:18px"><a href="https://github.com/WhisperYi/XRF55">Mengdie Zhu</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:18px"><a href="https://scholar.google.com/citations?user=LKPpmXQAAAAJ&hl=en">Fei Wang</a></span>
		  		  		</center>
		  		  	  </td>
			  </table><br>
     <span style="font-size:18px">Xi'an Jiaotong University, Shaanxi</span><br>
     <span style="font-size:18px">In ICCV 2077</span><br><br>
      <table align=center width=300px>
	  			  <tr>
	  	              <td align=center width=50px>
	  					<center>
	  						<span style="font-size:24px"><a href='https://github.com/WhisperYi/XRF55'>[Paper]</a>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=50px>
	  					<center>
	  						<span style="font-size:24px"><a href='https://github.com/WhisperYi/XRF55'>[GitHub]</a></span>
		  		  		</center>
		  		  	  </td>
			  </table>
</center>
<br>	
<table align=center width=850px>
  			  <tr>
  	              <td width=400px>
  					<center>
  	                	<a href="images/teaser_v3.jpg"><img class="" src = "images/teaser_v3.jpg" height="360px"></img></href></a><br>
					</center>
  	              </td>
                </tr>
  	              <td width=400px>
  	                	<span style="font-size:14px"><i>XYZ55 includes 55 human indoor action classes which we categorize into 5 types: Human-Object Interaction, Human-Human Interaction, Fitness, Body Motion, and Human-Computer Interaction..</i>
                 
  	              </td>

  		  </table>
          
          <table align=center width=850px>
	  		  <center><h1>Abstract</h1></center>
	  		  <tr>
	  		  	<td>
	  		    </td>
	  		  </tr>
			</table>
				In recent years, there has been a proliferation of works on human action classification from depth sequences. These works generally present methods and/or feature representations for the classification of actions from sequences of 3D locations of human body joints and/or other sources of data, such as depth maps and RGB videos. This survey highlights motivations and challenges of this very recent research area by presenting technologies and approaches for 3D skeleton-based action classification. The work focuses on aspects such as data pre-processing, publicly available benchmarks and commonly used accuracy measurements. Furthermore, this survey introduces a categorization of the most recent works in 3D skeleton-based action classification according to the adopted feature representation.
  		  <br><br>
		  <hr>

			<center><h1>Paper</h1></center>
			<table align="center" width="700" px="">
			          <tbody><tr>
			          <td><a href="https://github.com/WhisperYi/XRF55"><img class="layered-paper-big" style="height:175px" src="images/paper_pdf_thumb.png"></a></td>
			          <td><br><br><br><span style="font-size:12pt">Yizhe Lv, Mengdie Zhu, Fei Wang</span><br>
			          <b><span style="font-size:12pt">XYZ55: A temporary dataset for human indoor motion analysis</span></b><br>
			          <span style="font-size:12pt">ICCV, 2077 (<a href="https://github.com/WhisperYi/XRF55">Paper</a>)</span>
			          </td>
								</tr>
					</table>
								<br>
          <table align="center" width="600px">
            <tbody>
              <tr>
                <td>
                  <center>
                    <span style="font-size:22px">
                      <a href="./resources/bibtex_cvpr_pix2pix.txt" target="_blank">[bibtex]</a>
                    </span>
                  </center>
                </td>
              </tr>
            </tbody>
          </table>
			
		  <br><br>

          <hr>
          
          <center><h1>Download our dataset</h1></center><br>	<br>	

  		  <table align=center width=800px>
			  <tr><center>
				<!-- <span style="font-size:28px">Code coming soon!</span></i>			  	 -->
				<div style="width:600px; text-align:center">
					<span style="font-size:28px"><a href='https://github.com/WhisperYi/XRF55'>[Wi-Fi dataset]</a></span>&nbsp;&nbsp;
					<span style="font-size:28px"><a href='https://github.com/WhisperYi/XRF55'>[RFID dataset]</a></span>&nbsp;&nbsp;
                    <span style="font-size:28px"><a href='https://github.com/WhisperYi/XRF55'>[mmWave dataset]</a></span>&nbsp;&nbsp;
                    <span style="font-size:28px"><a href='https://github.com/WhisperYi/XRF55'>[Kinect dataset]</a></span>
				</div>
                    <br>
			  </center></tr>
		  </table>
          <br>
		  <hr>
          
          <center><h1>Slides and network structure</h1></center>
     		  <br>
     		  <table align=center width=1100px>
     			  <tr>
     	              <td width=300px>
     					<center>
     						<span style="font-size:22px"><a href="images/XYZ55.pptx">Slides</a></span><br>
                             <div class="slideshow-container">
                                <div class="mySlides fade">
                                  <div class="numbertext">1 / 5</div>
                                  <img decoding="async" src="images/s1.JPG" style="width:100%">
                                  <div class="text">文本 1</div>
                                </div>
                               
                                <div class="mySlides fade">
                                  <div class="numbertext">2 / 5</div>
                                  <img decoding="async" src="images/s2.JPG" style="width:100%">
                                  <div class="text">文本 2</div>
                                </div>
                               
                                <div class="mySlides fade">
                                  <div class="numbertext">3 / 5</div>
                                  <img decoding="async" src="images/s3.JPG" style="width:100%">
                                  <div class="text">文本 3</div>
                                </div>
                                <div class="mySlides fade">
                                    <div class="numbertext">4 / 5</div>
                                    <img decoding="async" src="images/s4.JPG" style="width:100%">
                                    <div class="text">文本 4</div>
                                  </div>
                                <div class="mySlides fade">
                                    <div class="numbertext">5 / 5</div>
                                    <img decoding="async" src="images/s5.JPG" style="width:100%">
                                    <div class="text">文本 5</div>
                                  </div>
                                <a class="prev" onclick="plusSlides(-1)">❮</a>
                                <a class="next" onclick="plusSlides(1)">❯</a>
                              </div>
                              <br>
                        </center>
     	              </td>

     	              <td width=300px>
     					<center>
     						<span style="font-size:22px"><a href='images/network.png'>Network structure</a></span><br>
     	                	<a href="images/network.png"><img src="images/network.png" width = "400px"></a><br>
						<br>
						<div style="width:400px; text-align:left">Great explanation by Christopher Hesse, also documenting his <a href="https://github.com/affinelayer/pix2pix-tensorflow">tensorflow port</a> of our code.</div>
			      </center>
     	              </td>

                   </tr>
     		  </table>
		  <br><br>
          <hr>
	<table align=center width=1100px>
		  <tr>
              <td width=400px>
     					<left>
      		  <center><h1>Prospect </h1></center>
              People can use our dataset for many creative applications,  due to the synchronized Kinect, we envision XRF55 will support and facilitate the exploration of action detection, action segmentation, pose estimation, human parsing, mesh reconstruction<br><br>

      		  <table align=center width=1100px>
							<tr>
      	              <td width=300px>
      					<center>
      						<span style="font-size:22px"><a href='https://www.nvidia.com/en-us/deep-learning-ai/ai-art-gallery/artists/scott-eaton/'>Human Allocation of Space</a></span><br>
      	                	<a href="https://www.nvidia.com/en-us/deep-learning-ai/ai-art-gallery/artists/scott-eaton/"><img src="images/color_palettes.jpg" width = "250px"></a><br>
      					<div style="width:250px; text-align:left; font-size:14px"><a href="http://www.scott-eaton.com/">Scott Eaton</a> uses a customized version of pix2pix as a tool in his artwork, for example training a net to <a href="https://vimeo.com/345881421">translate from sketches and brush strokes to 3D renderings</a>. The sculpture above is an actual brozne cast derived from one of Scott's translated designs. You can find more of his AI-empowered artwork <a href="http://www.scott-eaton.com/category/creativeai">here</a>.</div></center>
      	              </td>

      	              <td width=300px>
      					<center>
      						<span style="font-size:22px"><a href='https://vimeo.com/260612034'>Learning to See: Gloomy Sunday</a></span><br>
      	                	<a href="https://vimeo.com/260612034"><img src="images/color_palettes.jpg" width = "250px"></a><br>
      					<div style="width:250px; text-align:left; font-size:14px"><a href="http://www.memo.tv/">Memo Akten</a> used pix2pix to create the very compelling music video linked above, in which common household items, like a powercord, are moved around in a pantomine of crashing waves and blooming flowers. Then a pix2pix-based model translates the pantomine into renderings of the imagined objects.</div></center>
      	              </td>

      	              <td width=300px>
      					<center>
      						<span style="font-size:22px"><a href='https://nono.ma/suggestive-drawing'>Suggestive Drawing</a></span><br>
      	                	<a href="https://nono.ma/suggestive-drawing"><img src="images/color_palettes.jpg" width = "250px"></a><br>
      					<div style="width:250px; text-align:left; font-size:14px"><a href="https://nono.ma/">Nono Martinez Alonso</a> used pix2pix for his masters thesis on human-AI collaboration for design. Different pix2pix models are used as aids for a human designer, where they "suggest" extensions, refinements, and completions of the designer's sketches.</div></center>
      	              </td>

              </tr>
										
      			  <tr>
      	              <td width=300px>
												<br>
      					<center>
      						<span style="font-size:22px"><a href='https://twitter.com/search?vertical=default&q=edges2cats&src=typd'>#edges2cats</a></span><br>
      	                	<a href="https://twitter.com/search?vertical=default&q=edges2cats&src=typd"><img src="images/color_palettes.jpg" width = "250px"></a><br>
      					<div style="width:250px; text-align:left; font-size:14px"><a href="https://twitter.com/christophrhesse?lang=en">Christopher Hesse</a> trained our model on converting edge maps to photos of cats, and included this in his <a href="https://affinelayer.com/pixsrv/">interactive demo</a>. Apparently, this is what the Internet wanted most, and #edges2cats briefly <a href="https://www.youtube.com/watch?v=vbuE5CLRCDY">went viral</a>. The above cats were designed by Vitaly Vidmirov (<a href="https://twitter.com/vvid/status/834976420942204933">@vvid</a>).</div></center>
      	              </td>

      	              <td width=300px>
      					<center>
      						<span style="font-size:22px"><a href='https://www.youtube.com/watch?v=af_9LXhcebY'>Alternative Face</a></span><br>
      	                	<a href="https://www.youtube.com/watch?v=af_9LXhcebY"><img src="images/color_palettes.jpg" width = "250px"></a><br>
      					<div style="width:250px; text-align:left; font-size:14px"><a href="https://quasimondo.com/">Mario Klingemann</a> used our code to translate the appearance of French singer Francoise Hardy onto Kellyanne Conway's infamous "alternative facts" interview. Interesting articles about it can be read <a href="http://nymag.com/selectall/2017/03/pix2pix-cat-drawing-tool-is-ai-at-its-best.html">here</a> and <a href="http://www.alphr.com/art/1005324/alternative-face-the-machine-that-puts-kellyanne-conway-s-words-into-a-french-singer-s">here</a>.</div></center>
      	              </td>

      	              <td width=300px>
      					<center>
      						<span style="font-size:22px"><a href='https://twitter.com/brannondorsey/status/808461108881268736'>Person-to-Person</a></span><br>
      	                	<a href="https://twitter.com/brannondorsey/status/808461108881268736"><img src="images/color_palettes.jpg" width = "250px"></a><br>
      					<div style="width:250px; text-align:left; font-size:14px"><a href="https://brannondorsey.com/">Brannon Dorsey</a> recorded himself mimicking frames from a video of Ray Kurzweil giving a talk. He then used this data to train a Dorsey&rarr;Kurzweil translator, allowing him to become a kind of puppeter in control of Kurzweil's appearance.</div></center>
      	              </td>

                    </tr>

                    <tr>
        	              <td width=300px>
                              <br>
        					<center>
        						<span style="font-size:22px"><a href='https://twitter.com/bgondouin/status/818571935529377792'>Interactive Anime</a></span><br>
        	                	<a href="https://twitter.com/bgondouin/status/818571935529377792"><img src="images/color_palettes.jpg" width = "250px"></a><br>
        					<div style="width:250px; text-align:left; font-size:14px"><a href="https://bgon.github.io/">Bertrand Gondouin</a> trained our method to translate sketches&rarr;Pokemon, resulting in an interactive drawing tool.</div></center>
        	              </td>

        	              <td width=300px>
                              <br>
        					<center>
        						<span style="font-size:22px"><a href='http://www.k4ai.com/imageops/index.html'>Background masking</a></span><br>
        	                	<a href="http://www.k4ai.com/imageops/index.html"><img src="images/color_palettes.jpg" width = "250px"></a><br>
        					<div style="width:250px; text-align:left; font-size:14px"><a href="https://twitter.com/kaihuchen?lang=en">Kaihu Chen</a> performed <a href="http://www.k4ai.com/tag/gan/index.html">a number of interesting experiments</a> using our method, including getting it to mask out the background of a portrait as shown above.</div></center>
        	              </td>

      	              <td width=300px>
                          <br>
      					<center>
      						<span style="font-size:22px"><a href='http://colormind.io/blog/'>Color palette completion</a></span><br>
      	                	<a href="http://colormind.io/blog/"><img src="images/color_palettes.jpg" width = "250px"></a><br>
      					<div style="width:250px; text-align:left; font-size:14px"><a href="http://colormind.io/blog/">Colormind</a> adapted our code to predict a complete 5-color palette given a subset of the palette as input. This application stretches the definition of what counts as "image-to-image translation" in an exciting way: if you can visualize your input/output data as images, then image-to-image methods are applicable! (not that this is necessarily the best choice of representation, just one to think about.)</div></center>
      	              </td>

                    </tr>
      		  </table>
              <br>
        </td>
    </tr>
</table>
<br>
<hr>

  		  <table align=center width=1100px>
  			  <tr>
  	              <td>
  					<left>
	  		  <center><h1>Acknowledgements</h1></center>
					 <center>Thanks for watching.</center>
			</left>
		</td>
			 </tr>
		</table>

		<br><br>
</body>
</html>
<script>
    var slideIndex = 1;
showSlides(slideIndex);
 
function plusSlides(n) {
  showSlides(slideIndex += n);
}
 
function currentSlide(n) {
  showSlides(slideIndex = n);
}
 
function showSlides(n) {
  var i;
  var slides = document.getElementsByClassName("mySlides");
  var dots = document.getElementsByClassName("dot");
  if (n > slides.length) {slideIndex = 1} 
  if (n < 1) {slideIndex = slides.length}
  for (i = 0; i < slides.length; i++) {
      slides[i].style.display = "none"; 
  }
  for (i = 0; i < dots.length; i++) {
      dots[i].className = dots[i].className.replace(" active", "");
  }
  slides[slideIndex-1].style.display = "block"; 
  dots[slideIndex-1].className += " active";
}
</script>
